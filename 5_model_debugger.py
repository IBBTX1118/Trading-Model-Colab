# æª”å: 5_model_debugger.py (v2.1 - Colab ä¿®å¾©ç‰ˆ)
# æè¿°: ä¿®å¾©åœ¨Google Colabä¸­é‹è¡Œçš„èªæ³•éŒ¯èª¤å’Œå…¼å®¹æ€§å•é¡Œ

import pandas as pd
import lightgbm as lgb
import json
import numpy as np
from pathlib import Path
import matplotlib.pyplot as plt
import seaborn as sns
import yaml
import warnings

# è¨­ç½®matplotlibåœ¨Colabä¸­æ­£ç¢ºé¡¯ç¤º
import matplotlib
matplotlib.use('Agg')  # è¨­ç½®å¾Œç«¯
plt.ioff()  # é—œé–‰äº¤äº’æ¨¡å¼

# å¿½ç•¥è­¦å‘Šä¿¡æ¯
warnings.filterwarnings('ignore')

print("ğŸš€ æ¨¡å‹èª¿è©¦å·¥å…· - Colabä¿®å¾©ç‰ˆ (v2.1)")
print("="*60)

# --- è¨­å®šå€å¡Š ---
MARKET_NAME = "USDJPY_sml_H1"  # é¸æ“‡ä¸€å€‹å¸‚å ´ä¾†é€²è¡ŒåµéŒ¯
FEATURE_DATA_PATH = Path("Output_Feature_Engineering/MarketData_with_Combined_Features_v3")
ML_OUTPUT_PATH = Path("Output_ML_Pipeline")
CONFIG_PATH = Path("config.yaml")

print(f"ğŸ“Š ç›®æ¨™å¸‚å ´: {MARKET_NAME}")
print(f"ğŸ—‚ï¸  ç‰¹å¾µæ•¸æ“šè·¯å¾‘: {FEATURE_DATA_PATH}")
print(f"ğŸ“ MLè¼¸å‡ºè·¯å¾‘: {ML_OUTPUT_PATH}")

# --- 1. æª¢æŸ¥æª”æ¡ˆæ˜¯å¦å­˜åœ¨ ---
print("\nğŸ” æª¢æŸ¥æª”æ¡ˆ...")

market_folder = MARKET_NAME.split('_')[0] + "_" + MARKET_NAME.split('_')[1]
data_file = FEATURE_DATA_PATH / market_folder / f"{MARKET_NAME}.parquet"
features_file = ML_OUTPUT_PATH / f"selected_features_{MARKET_NAME}.json"

if not data_file.exists():
    print(f"âŒ æ•¸æ“šæª”æ¡ˆä¸å­˜åœ¨: {data_file}")
    print("ğŸ’¡ è«‹ç¢ºèªè·¯å¾‘è¨­å®šæ˜¯å¦æ­£ç¢º")
    exit(1)

if not features_file.exists():
    print(f"âŒ ç‰¹å¾µæª”æ¡ˆä¸å­˜åœ¨: {features_file}")
    print("ğŸ’¡ è«‹å…ˆé‹è¡Œ 03_feature_selection.py")
    exit(1)

if not CONFIG_PATH.exists():
    print(f"âš ï¸  é…ç½®æª”æ¡ˆä¸å­˜åœ¨: {CONFIG_PATH}ï¼Œä½¿ç”¨é»˜èªè¨­å®š")
    triple_barrier_settings = {
        'tp_atr_multiplier': 2.5,
        'sl_atr_multiplier': 1.5,
        'max_hold_periods': 24
    }
else:
    print(f"âœ… æ‰¾åˆ°é…ç½®æª”æ¡ˆ: {CONFIG_PATH}")

# --- 2. è¼‰å…¥æ•¸æ“šã€ç‰¹å¾µå’Œè¨­å®š ---
print("\nğŸ“‚ è¼‰å…¥æ•¸æ“šä¸­...")
try:
    df = pd.read_parquet(data_file)
    print(f"âœ… æ•¸æ“šè¼‰å…¥æˆåŠŸ: {df.shape}")
except Exception as e:
    print(f"âŒ æ•¸æ“šè¼‰å…¥å¤±æ•—: {e}")
    exit(1)

try:
    with open(features_file, 'r', encoding='utf-8') as f:
        features_data = json.load(f)
    selected_features = features_data['selected_features']
    print(f"âœ… ç‰¹å¾µè¼‰å…¥æˆåŠŸ: {len(selected_features)} å€‹ç‰¹å¾µ")
except Exception as e:
    print(f"âŒ ç‰¹å¾µè¼‰å…¥å¤±æ•—: {e}")
    exit(1)

# è¼‰å…¥config.yamlä»¥ç²å–æ¨™ç±¤è¨­å®š
if CONFIG_PATH.exists():
    try:
        with open(CONFIG_PATH, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        triple_barrier_settings = config['triple_barrier_settings']
        print(f"âœ… é…ç½®è¼‰å…¥æˆåŠŸ")
    except Exception as e:
        print(f"âš ï¸  é…ç½®è¼‰å…¥å¤±æ•—ï¼Œä½¿ç”¨é»˜èªè¨­å®š: {e}")
        triple_barrier_settings = {
            'tp_atr_multiplier': 2.5,
            'sl_atr_multiplier': 1.5,
            'max_hold_periods': 24
        }

print(f"ğŸ¯ æ¨™ç±¤è¨­å®š: TP={triple_barrier_settings['tp_atr_multiplier']}x ATR, SL={triple_barrier_settings['sl_atr_multiplier']}x ATR")

# --- 3. æª¢æŸ¥ç‰¹å¾µå¯ç”¨æ€§ ---
print("\nğŸ” æª¢æŸ¥ç‰¹å¾µå¯ç”¨æ€§...")
available_features = [f for f in selected_features if f in df.columns]
missing_features = [f for f in selected_features if f not in df.columns]

if missing_features:
    print(f"âš ï¸  ç¼ºå°‘ç‰¹å¾µ: {len(missing_features)} å€‹")
    if len(missing_features) <= 5:
        print(f"   ç¼ºå°‘çš„ç‰¹å¾µ: {missing_features}")
    else:
        print(f"   å‰5å€‹ç¼ºå°‘çš„ç‰¹å¾µ: {missing_features[:5]}")

if len(available_features) < 5:
    print(f"âŒ å¯ç”¨ç‰¹å¾µéå°‘ ({len(available_features)})ï¼Œç„¡æ³•é€²è¡Œèª¿è©¦")
    exit(1)

print(f"âœ… å¯ç”¨ç‰¹å¾µ: {len(available_features)}/{len(selected_features)}")

# --- 4. å‰µå»ºæ¨™ç±¤ä¸¦åˆ‡æ›è‡³äºŒåˆ†é¡æ¨¡å¼ (èˆ‡ 04 è…³æœ¬å®Œå…¨ä¸€è‡´) ---
print("\nğŸ·ï¸  å‰µå»ºæ¨™ç±¤ä¸¦æº–å‚™æ•¸æ“š...")

def create_triple_barrier_labels(df, settings):
    """å‰µå»ºä¸‰é“é–€æª»æ¨™ç±¤"""
    df_out = df.copy()
    tp_multiplier = settings['tp_atr_multiplier']
    sl_multiplier = settings['sl_atr_multiplier'] 
    max_hold = settings['max_hold_periods']
    
    # å°‹æ‰¾ATRæ¬„ä½
    atr_col_name = None
    for col in df_out.columns:
        if 'ATR_14' in col:
            atr_col_name = col
            break
    
    if not atr_col_name: 
        raise ValueError("âŒ ATRæ¬„ä½æœªæ‰¾åˆ°")
    
    print(f"âœ… ä½¿ç”¨ATRæ¬„ä½: {atr_col_name}")
    
    outcomes = pd.Series(index=df_out.index, dtype=float, name='label')
    high_series, low_series, atr_series = df_out['high'], df_out['low'], df_out[atr_col_name]

    valid_count = 0
    tp_count = 0
    sl_count = 0
    hold_count = 0

    print("ğŸ”„ è¨ˆç®—ä¸‰é“é–€æª»æ¨™ç±¤...")
    for i in range(len(df_out) - max_hold):
        if i % 5000 == 0:  # æ¯5000ç­†é¡¯ç¤ºé€²åº¦
            print(f"   é€²åº¦: {i}/{len(df_out) - max_hold}")
            
        entry_price, atr_at_entry = df_out['close'].iloc[i], atr_series.iloc[i]
        if atr_at_entry <= 0 or pd.isna(atr_at_entry): 
            continue
            
        valid_count += 1
        tp_price = entry_price + (atr_at_entry * tp_multiplier)
        sl_price = entry_price - (atr_at_entry * sl_multiplier)
        
        future_highs = high_series.iloc[i+1:i+1+max_hold]
        future_lows = low_series.iloc[i+1:i+1+max_hold]
        
        hit_tp_mask = future_highs >= tp_price
        hit_sl_mask = future_lows <= sl_price
        
        tp_hit_time = hit_tp_mask.idxmax() if hit_tp_mask.any() else pd.NaT
        sl_hit_time = hit_sl_mask.idxmax() if hit_sl_mask.any() else pd.NaT

        if pd.notna(tp_hit_time) and pd.notna(sl_hit_time): 
            if tp_hit_time <= sl_hit_time:
                outcomes.iloc[i] = 1
                tp_count += 1
            else:
                outcomes.iloc[i] = -1
                sl_count += 1
        elif pd.notna(tp_hit_time): 
            outcomes.iloc[i] = 1
            tp_count += 1
        elif pd.notna(sl_hit_time): 
            outcomes.iloc[i] = -1
            sl_count += 1
        else: 
            outcomes.iloc[i] = 0
            hold_count += 1
    
    print(f"âœ… æ¨™ç±¤çµ±è¨ˆ: æœ‰æ•ˆ={valid_count}, æ­¢ç›ˆ={tp_count}, æ­¢æ={sl_count}, æŒæœ‰={hold_count}")
    return df_out.join(outcomes.to_frame())

try:
    df_labeled = create_triple_barrier_labels(df, triple_barrier_settings)
except Exception as e:
    print(f"âŒ æ¨™ç±¤å‰µå»ºå¤±æ•—: {e}")
    exit(1)

# åªä¿ç•™æœ‰äº¤æ˜“ä¿¡è™Ÿçš„æ•¸æ“šï¼ˆæ’é™¤æŒæœ‰ï¼‰
df_trades_only = df_labeled[df_labeled['label'] != 0].copy()
df_trades_only['target_binary'] = (df_trades_only['label'] == 1).astype(int)

print(f"ğŸ“Š äº¤æ˜“ä¿¡è™Ÿåˆ†ä½ˆ:")
label_counts = df_trades_only['label'].value_counts().sort_index()
print(f"   æ­¢ç›ˆ (1):  {label_counts.get(1, 0):,} ç­†")
print(f"   æ­¢æ (-1): {label_counts.get(-1, 0):,} ç­†")

# æ¸…ç†æ•¸æ“š
df_trades_only.dropna(subset=available_features + ['target_binary'], inplace=True)

if df_trades_only.empty:
    print("âŒ æ¸…ç†å¾Œæ²’æœ‰å¯ç”¨çš„äº¤æ˜“æ•¸æ“š")
    exit(1)

print(f"âœ… æ¸…ç†å¾Œäº¤æ˜“æ•¸æ“š: {df_trades_only.shape}")

# åˆ†å‰²è¨“ç·´å’Œæ¸¬è©¦é›†
train_size = int(len(df_trades_only) * 0.8)
df_train = df_trades_only.iloc[:train_size]
df_test = df_trades_only.iloc[train_size:]

X_train = df_train[available_features]
y_train = df_train['target_binary']
X_test = df_test[available_features]
y_test = df_test['target_binary']

print(f"ğŸ“Š æ•¸æ“šåˆ†å‰²:")
print(f"   è¨“ç·´é›†: {X_train.shape}")
print(f"   æ¸¬è©¦é›†: {X_test.shape}")

# --- 5. è¨“ç·´æ¨¡å‹ ---
print("\nğŸ¤– è¨“ç·´æ¨¡å‹...")

neg_count = (y_train == 0).sum()
pos_count = (y_train == 1).sum()
scale_pos_weight = neg_count / pos_count if pos_count > 0 else 1

print(f"ğŸ“Š è¨“ç·´é›†æ¨™ç±¤åˆ†ä½ˆ:")
print(f"   æ­¢æ (0): {neg_count:,} ç­†")
print(f"   æ­¢ç›ˆ (1): {pos_count:,} ç­†")
print(f"   æ¬Šé‡å¹³è¡¡: {scale_pos_weight:.2f}")

try:
    model = lgb.LGBMClassifier(
        objective='binary', 
        scale_pos_weight=scale_pos_weight,
        verbosity=-1,
        random_state=42
    )
    model.fit(X_train, y_train)
    print("âœ… æ¨¡å‹è¨“ç·´æˆåŠŸ")
except Exception as e:
    print(f"âŒ æ¨¡å‹è¨“ç·´å¤±æ•—: {e}")
    exit(1)

# --- 6. åœ¨æ¸¬è©¦é›†ä¸Šé€²è¡Œæ‰¹é‡é æ¸¬ ---
print("\nğŸ” åœ¨æ¸¬è©¦é›†ä¸Šé€²è¡Œé æ¸¬...")

try:
    win_probabilities = model.predict_proba(X_test)[:, 1]
    print(f"âœ… é æ¸¬å®Œæˆ: {len(win_probabilities)} å€‹é æ¸¬çµæœ")
except Exception as e:
    print(f"âŒ é æ¸¬å¤±æ•—: {e}")
    exit(1)

# --- 7. è¦–è¦ºåŒ–é æ¸¬æ¦‚ç‡åˆ†ä½ˆ ---
print("\nğŸ“Š ç¹ªè£½æ¨¡å‹ä¿¡å¿ƒåˆ†ä½ˆåœ–...")

try:
    # è¨­ç½®åœ–è¡¨æ¨£å¼ - ä½¿ç”¨å…¼å®¹çš„æ¨£å¼
    plt.style.use('default')  # ä½¿ç”¨é»˜èªæ¨£å¼è€Œä¸æ˜¯å¯èƒ½ä¸å­˜åœ¨çš„seabornæ¨£å¼
    
    fig, ax = plt.subplots(figsize=(12, 7))
    
    # ä½¿ç”¨matplotlibç›´æ¥ç¹ªè£½ç›´æ–¹åœ–ï¼Œé¿å…seabornç‰ˆæœ¬å•é¡Œ
    ax.hist(win_probabilities, bins=20, alpha=0.7, color='skyblue', edgecolor='black')
    
    ax.set_title(f'æ¨¡å‹é æ¸¬å‹ç‡ (P(Win)) çš„åˆ†ä½ˆ - {MARKET_NAME}', fontsize=16)
    ax.set_xlabel('é æ¸¬çš„å‹ç‡ (Win Probability)', fontsize=12)
    ax.set_ylabel('ä¿¡è™Ÿæ•¸é‡ (Frequency)', fontsize=12)
    ax.axvline(x=0.5, color='red', linestyle='--', linewidth=2, label='éš¨æ©ŸçŒœæ¸¬ (50%)')
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()
    print("âœ… åœ–è¡¨é¡¯ç¤ºæˆåŠŸ")
    
except Exception as e:
    print(f"âŒ åœ–è¡¨é¡¯ç¤ºå¤±æ•—: {e}")
    print("ğŸ’¡ é€™å¯èƒ½æ˜¯ç”±æ–¼ç’°å¢ƒé…ç½®å•é¡Œï¼Œä½†ä¸å½±éŸ¿åˆ†æçµæœ")

# --- 8. è¨ºæ–·åˆ†æ ---
print("\n" + "="*60)
print("ğŸ” è¨ºæ–·åˆ†æ:")
print("="*60)

avg_prob = np.mean(win_probabilities)
std_prob = np.std(win_probabilities)
min_prob = np.min(win_probabilities)
max_prob = np.max(win_probabilities)

confident_buys = np.sum(win_probabilities > 0.6)
confident_sells = np.sum(win_probabilities < 0.4)
uncertain_signals = np.sum((win_probabilities >= 0.4) & (win_probabilities <= 0.6))

print(f"ğŸ“Š é æ¸¬æ¦‚ç‡çµ±è¨ˆ:")
print(f"   å¹³å‡é æ¸¬å‹ç‡: {avg_prob:.2%}")
print(f"   æ¨™æº–å·®: {std_prob:.2%}")
print(f"   æœ€å°å€¼: {min_prob:.2%}")
print(f"   æœ€å¤§å€¼: {max_prob:.2%}")

print(f"\nğŸ¯ ä¿¡è™Ÿåˆ†é¡:")
print(f"   é«˜ä¿¡å¿ƒè²·å…¥ä¿¡è™Ÿ (>60%): {confident_buys} / {len(win_probabilities)} ({confident_buys/len(win_probabilities):.1%})")
print(f"   é«˜ä¿¡å¿ƒè³£å‡ºä¿¡è™Ÿ (<40%): {confident_sells} / {len(win_probabilities)} ({confident_sells/len(win_probabilities):.1%})")
print(f"   ä¸ç¢ºå®šä¿¡è™Ÿ (40%-60%): {uncertain_signals} / {len(win_probabilities)} ({uncertain_signals/len(win_probabilities):.1%})")

# --- 9. æ¦‚ç‡åˆ†å¸ƒåˆ†æ ---
print(f"\nğŸ“Š æ¦‚ç‡å€é–“åˆ†ä½ˆ:")
bins = [(0, 0.2), (0.2, 0.4), (0.4, 0.6), (0.6, 0.8), (0.8, 1.0)]
for i, (low, high) in enumerate(bins):
    count = np.sum((win_probabilities >= low) & (win_probabilities < high))
    percentage = count / len(win_probabilities) * 100
    print(f"   {low*100:2.0f}%-{high*100:2.0f}%: {count:4d} ç­† ({percentage:5.1f}%)")

print("="*60)

# --- 10. æ¨¡å‹è¨ºæ–·å»ºè­° ---
print("\nğŸ’¡ è¨ºæ–·å»ºè­°:")

if std_prob < 0.05:
    print("âš ï¸  ã€å•é¡Œã€‘: é æ¸¬æ¦‚ç‡æ¨™æº–å·®éå°ï¼Œæ¨¡å‹å¯èƒ½éæ–¼ä¿å®ˆ")
    print("   å»ºè­°: æª¢æŸ¥ç‰¹å¾µå·¥ç¨‹ï¼Œå¢åŠ æ›´å¤šåˆ¤åˆ¥æ€§ç‰¹å¾µ")

if avg_prob > 0.6 or avg_prob < 0.4:
    print("âš ï¸  ã€å•é¡Œã€‘: å¹³å‡é æ¸¬æ¦‚ç‡åé›¢50%éå¤šï¼Œå¯èƒ½å­˜åœ¨åè¦‹")
    print("   å»ºè­°: æª¢æŸ¥æ¨™ç±¤å‰µå»ºé‚è¼¯å’Œæ¨£æœ¬å¹³è¡¡")

if uncertain_signals / len(win_probabilities) > 0.7:
    print("âš ï¸  ã€å•é¡Œã€‘: è¶…é70%çš„ä¿¡è™Ÿé›†ä¸­åœ¨40%-60%å€é–“ï¼Œæ¨¡å‹ä¿¡å¿ƒåº¦ä¸è¶³")
    print("   å»ºè­°: å¢åŠ æ›´å¤šæœ‰åˆ¤åˆ¥åŠ›çš„ç‰¹å¾µï¼Œæˆ–èª¿æ•´æ¨¡å‹åƒæ•¸")

if (confident_buys + confident_sells) / len(win_probabilities) > 0.5:
    print("âœ… ã€è‰¯å¥½ã€‘: è¶…é50%çš„ä¿¡è™Ÿå…·æœ‰è¼ƒé«˜ä¿¡å¿ƒåº¦")

print("\nğŸ¯ ç†æƒ³åˆ†ä½ˆç‰¹å¾µ:")
print("   - é æ¸¬æ¦‚ç‡æ‡‰å‘ˆç¾é›™å³°åˆ†ä½ˆï¼ˆUå‹ï¼‰")
print("   - å¤§é‡ä¿¡è™Ÿé›†ä¸­åœ¨0-20%å’Œ80-100%å€é–“") 
print("   - 40-60%å€é–“çš„ä¿¡è™Ÿæ‡‰ç›¡å¯èƒ½å°‘")
print("   - æ¨™æº–å·®æ‡‰å¤§æ–¼10%ä»¥ä¿è­‰æ¨¡å‹åˆ¤åˆ¥èƒ½åŠ›")

print("\nğŸ‰ èª¿è©¦å®Œæˆï¼")
print("="*60)
