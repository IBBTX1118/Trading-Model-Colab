# æª”å: 05_model_debugger.py
# æè¿°: æ¨¡å‹èª¿è©¦å·¥å…·ï¼Œç”¨æ–¼è¨ºæ–·é æ¸¬é‚è¼¯å’Œæª¢æŸ¥æ•¸æ“šå“è³ª
# ç‰ˆæœ¬: 1.1 (ä¿®å¾©ç‰ˆ - åŒ…å«å®Œæ•´æ¨™ç±¤å‰µå»ºé‚è¼¯)

import pandas as pd
import numpy as np
import lightgbm as lgb
import json
import yaml
from pathlib import Path
import sys

# ==============================================================================
#                      æ¨™ç±¤å‰µå»ºå‡½æ•¸ (èˆ‡04è…³æœ¬ä¿æŒä¸€è‡´)
# ==============================================================================
def create_adaptive_labels(df: pd.DataFrame, settings: dict) -> pd.DataFrame:
    """è‡ªé©æ‡‰æ¨™ç±¤å‰µå»ºï¼Œæ ¹æ“šå¸‚å ´ç‹€æ…‹å‹•æ…‹èª¿æ•´æ­¢ç›ˆæ­¢æ"""
    df_out = df.copy()
    
    # åŸºç¤å€æ•¸
    tp_multiplier_base = settings['tp_atr_multiplier']
    sl_multiplier_base = settings['sl_atr_multiplier']
    max_hold = settings['max_hold_periods']
    
    # ç‹€æ…‹èª¿æ•´å› å­
    regime_adjustment = {
        0: 0.8,  # ä½æ³¢å‹•ç›¤æ•´: æ”¶ç·Šç›®æ¨™
        1: 0.9,  # ä½æ³¢å‹•è¶¨å‹¢: ç•¥å¾®æ”¶ç·Š
        2: 1.1,  # é«˜æ³¢å‹•ç›¤æ•´: ç•¥å¾®æ”¾å¤§
        3: 1.2   # é«˜æ³¢å‹•è¶¨å‹¢: æ”¾å¤§ç›®æ¨™
    }
    
    # æª¢æŸ¥ market_regime æ˜¯å¦å­˜åœ¨
    if 'market_regime' in df_out.columns:
        df_out['tp_multiplier_adj'] = df_out['market_regime'].map(regime_adjustment) * tp_multiplier_base
        df_out['sl_multiplier_adj'] = df_out['market_regime'].map(regime_adjustment) * sl_multiplier_base
        print("âœ… ä½¿ç”¨å¸‚å ´ç‹€æ…‹è‡ªé©æ‡‰èª¿æ•´æ­¢ç›ˆæ­¢æå€æ•¸")
    else:
        # å¦‚æœæ²’æœ‰ç‹€æ…‹ç‰¹å¾µï¼Œå‰‡é€€å›ä½¿ç”¨å›ºå®šå€æ•¸
        df_out['tp_multiplier_adj'] = tp_multiplier_base
        df_out['sl_multiplier_adj'] = sl_multiplier_base
        print("âš ï¸  æœªæ‰¾åˆ° market_regime ç‰¹å¾µï¼Œä½¿ç”¨å›ºå®šæ­¢ç›ˆæ­¢æå€æ•¸")
    
    # æª¢æŸ¥ATRæ¬„ä½
    atr_col_name = None
    for col in df_out.columns:
        if 'D1_ATR_14' in col:
            atr_col_name = col
            break
        elif 'ATR_14' in col:
            atr_col_name = col
            
    if atr_col_name is None:
        raise ValueError(f"âŒ æ•¸æ“šä¸­ç¼ºå°‘ ATR æ¬„ä½ï¼Œç„¡æ³•å‰µå»ºæ¨™ç±¤ã€‚")
    
    print(f"âœ… ä½¿ç”¨ATRæ¬„ä½: {atr_col_name}")
    
    # å‰µå»ºæ¨™ç±¤çµæœ
    outcomes = pd.Series(index=df_out.index, dtype=float, name='label')
    
    high_series, low_series, atr_series = df_out['high'], df_out['low'], df_out[atr_col_name]
    tp_multipliers, sl_multipliers = df_out['tp_multiplier_adj'], df_out['sl_multiplier_adj']
    
    valid_count = 0
    tp_count = 0
    sl_count = 0
    hold_count = 0
    
    print("ğŸ”„ é–‹å§‹è¨ˆç®—ä¸‰é“é–€æª»æ¨™ç±¤...")
    
    # ç‚ºæ¯å€‹æ™‚é–“é»è¨ˆç®—ä¸‰é“é–€æª»æ¨™ç±¤
    for i in range(len(df_out) - max_hold):
        if i % 1000 == 0:  # æ¯1000ç­†é¡¯ç¤ºé€²åº¦
            print(f"   è™•ç†é€²åº¦: {i}/{len(df_out) - max_hold}")
            
        entry_price = df_out['close'].iloc[i]
        atr_at_entry = atr_series.iloc[i]
        tp_multiplier = tp_multipliers.iloc[i]
        sl_multiplier = sl_multipliers.iloc[i]
        
        # æª¢æŸ¥æ•¸æ“šæœ‰æ•ˆæ€§
        if atr_at_entry <= 0 or pd.isna(atr_at_entry) or pd.isna(tp_multiplier) or pd.isna(sl_multiplier):
            continue
            
        valid_count += 1
        
        # è¨ˆç®—è‡ªé©æ‡‰çš„æ­¢ç›ˆæ­¢æåƒ¹æ ¼
        tp_price = entry_price + (atr_at_entry * tp_multiplier)
        sl_price = entry_price - (atr_at_entry * sl_multiplier)
        
        # æª¢æŸ¥æœªä¾†åƒ¹æ ¼è¡Œç‚º
        future_highs = high_series.iloc[i+1:i+1+max_hold]
        future_lows = low_series.iloc[i+1:i+1+max_hold]
        
        if future_highs.empty or future_lows.empty:
            continue
            
        # æª¢æŸ¥è§¸åŠæ¢ä»¶
        hit_tp_mask = future_highs >= tp_price
        hit_sl_mask = future_lows <= sl_price
        
        tp_hit = hit_tp_mask.any()
        sl_hit = hit_sl_mask.any()
        
        if tp_hit and sl_hit:
            # éƒ½è§¸åŠï¼Œçœ‹èª°å…ˆ
            tp_first_idx = hit_tp_mask.idxmax() if tp_hit else None
            sl_first_idx = hit_sl_mask.idxmax() if sl_hit else None
            
            if tp_first_idx <= sl_first_idx:
                outcomes.iloc[i] = 1
                tp_count += 1
            else:
                outcomes.iloc[i] = -1
                sl_count += 1
        elif tp_hit:
            outcomes.iloc[i] = 1
            tp_count += 1
        elif sl_hit:
            outcomes.iloc[i] = -1
            sl_count += 1
        else:
            outcomes.iloc[i] = 0
            hold_count += 1
    
    print(f"âœ… è‡ªé©æ‡‰æ¨™ç±¤çµ±è¨ˆ: æœ‰æ•ˆ={valid_count}, æ­¢ç›ˆ={tp_count}, æ­¢æ={sl_count}, æŒæœ‰={hold_count}")
    
    # åˆä½µçµæœä¸¦å‰µå»ºç›®æ¨™è®Šæ•¸
    df_out = df_out.join(outcomes.to_frame())
    df_out['target'] = (df_out['label'] == 1).astype(int)
    
    # æ¸…ç†è‡¨æ™‚æ¬„ä½
    df_out.drop(columns=['tp_multiplier_adj', 'sl_multiplier_adj'], inplace=True, errors='ignore')
    
    return df_out

def load_config(config_path: str = 'config.yaml') -> dict:
    """è¼‰å…¥é…ç½®æª”æ¡ˆ"""
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)
    except FileNotFoundError:
        print(f"âš ï¸  è­¦å‘Š: æ‰¾ä¸åˆ°é…ç½®æª”æ¡ˆ {config_path}ï¼Œä½¿ç”¨é»˜èªè¨­ç½®")
        return {
            'triple_barrier_settings': {
                'tp_atr_multiplier': 2.5,
                'sl_atr_multiplier': 1.5,
                'max_hold_periods': 24
            }
        }
    except Exception as e:
        print(f"âŒ è®€å–é…ç½®æª”æ¡ˆå¤±æ•—: {e}")
        return {}

# ==============================================================================
#                      ä¸»ç¨‹åº
# ==============================================================================
def main():
    print("ğŸš€ æ¨¡å‹èª¿è©¦å·¥å…·å•Ÿå‹• (ç‰ˆæœ¬ 1.1)")
    print("="*60)
    
    # --- è¨­å®šå€å¡Š ---
    MARKET_NAME = "EURUSD_sml_H4"  # å¯ä»¥ä¿®æ”¹ç‚ºå…¶ä»–å¸‚å ´
    FEATURE_DATA_PATH = Path("Output_Feature_Engineering/MarketData_with_Combined_Features_v3")
    ML_OUTPUT_PATH = Path("Output_ML_Pipeline")
    USE_ADAPTIVE_LABELS = True  # æ˜¯å¦ä½¿ç”¨è‡ªé©æ‡‰æ¨™ç±¤
    
    print(f"ğŸ“Š ç›®æ¨™å¸‚å ´: {MARKET_NAME}")
    print(f"ğŸ—‚ï¸  ç‰¹å¾µæ•¸æ“šè·¯å¾‘: {FEATURE_DATA_PATH}")
    print(f"ğŸ“ MLè¼¸å‡ºè·¯å¾‘: {ML_OUTPUT_PATH}")
    print(f"ğŸ¯ æ¨™ç±¤æ–¹æ³•: {'è‡ªé©æ‡‰æ¨™ç±¤' if USE_ADAPTIVE_LABELS else 'å›ºå®šå€æ•¸æ¨™ç±¤'}")
    print("-"*60)
    
    # --- 1. è¼‰å…¥é…ç½® ---
    print("ğŸ”§ è¼‰å…¥é…ç½®æª”æ¡ˆ...")
    config = load_config()
    tb_settings = config.get('triple_barrier_settings', {
        'tp_atr_multiplier': 2.5,
        'sl_atr_multiplier': 1.5,
        'max_hold_periods': 24
    })
    print(f"âœ… ä¸‰é“é–€æª»è¨­å®š: TP={tb_settings['tp_atr_multiplier']}x ATR, SL={tb_settings['sl_atr_multiplier']}x ATR, æŒæœ‰={tb_settings['max_hold_periods']}æœŸ")
    
    # --- 2. è¼‰å…¥æ•¸æ“šå’Œç‰¹å¾µ ---
    print("\nğŸ“‚ è¼‰å…¥æ•¸æ“šå’Œç‰¹å¾µæª”æ¡ˆ...")
    
    # æ§‹å»ºæª”æ¡ˆè·¯å¾‘
    market_folder = MARKET_NAME.split('_')[0] + "_" + MARKET_NAME.split('_')[1]
    data_file = FEATURE_DATA_PATH / market_folder / f"{MARKET_NAME}.parquet"
    features_file = ML_OUTPUT_PATH / f"selected_features_{MARKET_NAME}.json"
    
    # æª¢æŸ¥æª”æ¡ˆæ˜¯å¦å­˜åœ¨
    if not data_file.exists():
        print(f"âŒ æ•¸æ“šæª”æ¡ˆä¸å­˜åœ¨: {data_file}")
        return
        
    if not features_file.exists():
        print(f"âŒ ç‰¹å¾µæª”æ¡ˆä¸å­˜åœ¨: {features_file}")
        print("ğŸ’¡ æç¤º: è«‹å…ˆé‹è¡Œ 03_feature_selection.py ç”Ÿæˆç‰¹å¾µæª”æ¡ˆ")
        return
    
    # è¼‰å…¥æ•¸æ“š
    print(f"ğŸ“Š è¼‰å…¥æ•¸æ“šæª”æ¡ˆ: {data_file.name}")
    df = pd.read_parquet(data_file)
    print(f"   æ•¸æ“šå½¢ç‹€: {df.shape}")
    print(f"   æ™‚é–“ç¯„åœ: {df.index.min()} åˆ° {df.index.max()}")
    
    # è¼‰å…¥ç‰¹å¾µ
    print(f"ğŸ¯ è¼‰å…¥ç‰¹å¾µæª”æ¡ˆ: {features_file.name}")
    with open(features_file, 'r', encoding='utf-8') as f:
        features_data = json.load(f)
    selected_features = features_data['selected_features']
    print(f"   é¸ä¸­ç‰¹å¾µæ•¸é‡: {len(selected_features)}")
    
    # æª¢æŸ¥ç‰¹å¾µå¯ç”¨æ€§
    available_features = [f for f in selected_features if f in df.columns]
    missing_features = [f for f in selected_features if f not in df.columns]
    
    if missing_features:
        print(f"âš ï¸  ç¼ºå°‘ç‰¹å¾µ: {missing_features[:5]}{'...' if len(missing_features) > 5 else ''}")
        print(f"   (å…± {len(missing_features)} å€‹ç¼ºå°‘ç‰¹å¾µ)")
    
    if len(available_features) < 5:
        print(f"âŒ å¯ç”¨ç‰¹å¾µéå°‘ ({len(available_features)})ï¼Œç„¡æ³•é€²è¡Œèª¿è©¦")
        return
    
    print(f"âœ… ä½¿ç”¨ {len(available_features)}/{len(selected_features)} å€‹ç‰¹å¾µ")
    
    # --- 3. å‰µå»ºæ¨™ç±¤ ---
    print("\nğŸ·ï¸  å‰µå»ºæ¨™ç±¤...")
    if USE_ADAPTIVE_LABELS:
        df_labeled = create_adaptive_labels(df, tb_settings)
    else:
        print("âš ï¸  å›ºå®šå€æ•¸æ¨™ç±¤å‰µå»ºé‚è¼¯æœªå¯¦ç¾ï¼Œè«‹ä½¿ç”¨è‡ªé©æ‡‰æ¨™ç±¤")
        return
    
    # å‰µå»ºå¤šåˆ†é¡ç›®æ¨™è®Šæ•¸
    mapping = {1: 1, -1: 0, 0: 2}  # æ­¢ç›ˆ:1, æ­¢æ:0, æŒæœ‰:2
    df_labeled['target_multiclass'] = df_labeled['label'].map(mapping)
    
    # æª¢æŸ¥æ¨™ç±¤åˆ†ä½ˆ
    label_counts = df_labeled['label'].value_counts().sort_index()
    class_counts = df_labeled['target_multiclass'].value_counts().sort_index()
    
    print(f"ğŸ“Š æ¨™ç±¤åˆ†ä½ˆ:")
    print(f"   æ­¢ç›ˆ (1):  {label_counts.get(1, 0):,} ç­†")
    print(f"   æ­¢æ (-1): {label_counts.get(-1, 0):,} ç­†")
    print(f"   æŒæœ‰ (0):  {label_counts.get(0, 0):,} ç­†")
    print(f"ğŸ“Š åˆ†é¡æ¨™ç±¤åˆ†ä½ˆ:")
    print(f"   Class 0 (æ­¢æ): {class_counts.get(0, 0):,} ç­†")
    print(f"   Class 1 (æ­¢ç›ˆ): {class_counts.get(1, 0):,} ç­†")
    print(f"   Class 2 (æŒæœ‰): {class_counts.get(2, 0):,} ç­†")
    
    # --- 4. æº–å‚™è¨“ç·´æ•¸æ“š ---
    print("\nğŸ”§ æº–å‚™è¨“ç·´æ•¸æ“š...")
    train_data = df_labeled.dropna(subset=available_features + ['target_multiclass', 'label'])
    
    if train_data.empty:
        print("âŒ æ¸…ç†å¾Œæ•¸æ“šç‚ºç©ºï¼Œç„¡æ³•é€²è¡Œèª¿è©¦")
        return
        
    print(f"âœ… æ¸…ç†å¾Œæ•¸æ“šå½¢ç‹€: {train_data.shape}")
    
    X_train = train_data[available_features]
    y_train = train_data['target_multiclass']
    
    # --- 5. è¨“ç·´èª¿è©¦æ¨¡å‹ ---
    print("\nğŸ¤– è¨“ç·´èª¿è©¦æ¨¡å‹...")
    model_params = {
        'objective': 'multiclass',
        'num_class': 3,
        'metric': 'multi_logloss',
        'verbosity': -1,
        'seed': 42,
        'n_estimators': 100  # è¼ƒå°‘çš„æ¨¹ï¼ŒåŠ å¿«èª¿è©¦é€Ÿåº¦
    }
    
    model = lgb.LGBMClassifier(**model_params)
    
    try:
        model.fit(X_train, y_train)
        print("âœ… æ¨¡å‹è¨“ç·´å®Œç•¢")
    except Exception as e:
        print(f"âŒ æ¨¡å‹è¨“ç·´å¤±æ•—: {e}")
        return
    
    # --- 6. é€²è¡Œå–®é»é æ¸¬èˆ‡é©—è­‰ ---
    print("\n" + "="*60)
    print("ğŸ” å–®é»é æ¸¬èˆ‡é©—è­‰")
    print("="*60)
    
    # é¸æ“‡æ¸¬è©¦æ¨£æœ¬
    if len(X_train) < 1000:
        sample_index = len(X_train) // 2
    else:
        sample_index = 1000
    
    X_sample = X_train.iloc[[sample_index]]
    y_true_label = train_data['label'].iloc[sample_index]
    y_true_class = train_data['target_multiclass'].iloc[sample_index]
    
    # é€²è¡Œé æ¸¬
    try:
        pred_probs = model.predict_proba(X_sample)[0]
    except Exception as e:
        print(f"âŒ é æ¸¬å¤±æ•—: {e}")
        return
    
    # è§£æé æ¸¬çµæœ
    prob_sl = pred_probs[0]    # Class 0: æ­¢æ
    prob_tp = pred_probs[1]    # Class 1: æ­¢ç›ˆ  
    prob_hold = pred_probs[2]  # Class 2: æŒæœ‰
    
    print(f"ğŸ• æ¨£æœ¬æ™‚é–“: {X_sample.index[0]}")
    print(f"ğŸ“ æ¨£æœ¬ç´¢å¼•: {sample_index}")
    print("-" * 60)
    print(f"ğŸ¤– æ¨¡å‹é æ¸¬æ¦‚ç‡:")
    print(f"   ğŸ“ˆ P(æ­¢ç›ˆ):  {prob_tp:.2%}")
    print(f"   ğŸ“‰ P(æ­¢æ):  {prob_sl:.2%}")
    print(f"   â¸ï¸  P(æŒæœ‰):  {prob_hold:.2%}")
    
    predicted_class = pred_probs.argmax()
    confidence = pred_probs.max() - np.sort(pred_probs)[-2]
    
    print("-" * 60)
    print(f"ğŸ“Š é æ¸¬çµæœ:")
    print(f"   ğŸ¯ é æ¸¬é¡åˆ¥: {predicted_class} ({'æ­¢æ' if predicted_class == 0 else 'æ­¢ç›ˆ' if predicted_class == 1 else 'æŒæœ‰'})")
    print(f"   ğŸª é æ¸¬ä¿¡å¿ƒåº¦: {confidence:.2%}")
    
    print("-" * 60)
    print(f"ğŸ“‹ çœŸå¯¦æ¨™ç±¤ (Ground Truth):")
    print(f"   ğŸ·ï¸  çœŸå¯¦ Label: {y_true_label} ({'æ­¢ç›ˆ' if y_true_label == 1 else 'æ­¢æ' if y_true_label == -1 else 'æŒæœ‰'})")
    print(f"   ğŸ·ï¸  çœŸå¯¦ Class: {y_true_class}")
    print("="*60)
    
    # --- 7. é‚è¼¯è¨ºæ–· ---
    print("ğŸ” é‚è¼¯è¨ºæ–·:")
    
    diagnosis_correct = False
    if predicted_class == 1 and y_true_label == 1:
        print("âœ… é‚è¼¯æ­£ç¢ºï¼šæ¨¡å‹é æ¸¬'æ­¢ç›ˆ'ï¼Œå¯¦éš›ä¹Ÿç‚º'æ­¢ç›ˆ'ã€‚")
        diagnosis_correct = True
    elif predicted_class == 0 and y_true_label == -1:
        print("âœ… é‚è¼¯æ­£ç¢ºï¼šæ¨¡å‹é æ¸¬'æ­¢æ'ï¼Œå¯¦éš›ä¹Ÿç‚º'æ­¢æ'ã€‚")
        diagnosis_correct = True
    elif predicted_class == 2 and y_true_label == 0:
        print("âœ… é‚è¼¯æ­£ç¢ºï¼šæ¨¡å‹é æ¸¬'æŒæœ‰'ï¼Œå¯¦éš›ä¹Ÿç‚º'æŒæœ‰'ã€‚")
        diagnosis_correct = True
    elif predicted_class == 1 and y_true_label == -1:
        print("âŒ é‚è¼¯åè½‰ï¼šæ¨¡å‹é æ¸¬'æ­¢ç›ˆ'ï¼Œä½†å¯¦éš›ç‚º'æ­¢æ'ï¼é€™æ˜¯å•é¡Œçš„æ ¹æºï¼")
    elif predicted_class == 0 and y_true_label == 1:
        print("âŒ é‚è¼¯åè½‰ï¼šæ¨¡å‹é æ¸¬'æ­¢æ'ï¼Œä½†å¯¦éš›ç‚º'æ­¢ç›ˆ'ï¼é€™æ˜¯å•é¡Œçš„æ ¹æºï¼")
    else:
        print("â„¹ï¸  æ¨¡å‹é æ¸¬èˆ‡å¯¦éš›æ¨™ç±¤ä¸ç¬¦ï¼Œä½†éç›´æ¥åè½‰ (ä¾‹å¦‚é æ¸¬æŒæœ‰ä½†å¯¦éš›æ­¢ç›ˆ/æ)ã€‚")
    
    print(f"ğŸ¯ å–®æ¨£æœ¬æº–ç¢ºæ€§: {'æ­£ç¢º' if diagnosis_correct else 'éŒ¯èª¤'}")
    
    # --- 8. æ‰¹é‡é©—è­‰ ---
    print("\n" + "="*60)
    print("ğŸ“Š æ‰¹é‡é©—è­‰ (éš¨æ©Ÿé¸å–100å€‹æ¨£æœ¬)")
    print("="*60)
    
    # éš¨æ©Ÿé¸å–æ¨£æœ¬é€²è¡Œæ‰¹é‡æ¸¬è©¦
    test_indices = np.random.choice(len(X_train), min(100, len(X_train)), replace=False)
    
    correct_predictions = 0
    logic_reversals = 0
    
    for idx in test_indices:
        X_test = X_train.iloc[[idx]]
        y_true_label_test = train_data['label'].iloc[idx]
        
        pred_probs_test = model.predict_proba(X_test)[0]
        predicted_class_test = pred_probs_test.argmax()
        
        # æª¢æŸ¥é æ¸¬æ­£ç¢ºæ€§
        if (predicted_class_test == 1 and y_true_label_test == 1) or \
           (predicted_class_test == 0 and y_true_label_test == -1) or \
           (predicted_class_test == 2 and y_true_label_test == 0):
            correct_predictions += 1
        
        # æª¢æŸ¥é‚è¼¯åè½‰
        if (predicted_class_test == 1 and y_true_label_test == -1) or \
           (predicted_class_test == 0 and y_true_label_test == 1):
            logic_reversals += 1
    
    accuracy = correct_predictions / len(test_indices)
    reversal_rate = logic_reversals / len(test_indices)
    
    print(f"ğŸ“ˆ æ‰¹é‡æ¸¬è©¦çµæœ:")
    print(f"   ğŸ¯ æº–ç¢ºç‡: {accuracy:.2%} ({correct_predictions}/{len(test_indices)})")
    print(f"   ğŸ”„ é‚è¼¯åè½‰ç‡: {reversal_rate:.2%} ({logic_reversals}/{len(test_indices)})")
    
    if reversal_rate > 0.1:  # å¦‚æœåè½‰ç‡è¶…é10%
        print("âš ï¸  è­¦å‘Š: é‚è¼¯åè½‰ç‡è¼ƒé«˜ï¼Œå¯èƒ½å­˜åœ¨æ¨™ç±¤å‰µå»ºæˆ–æ˜ å°„å•é¡Œï¼")
    elif accuracy > 0.6:
        print("âœ… æ¨¡å‹é‚è¼¯åŸºæœ¬æ­£å¸¸")
    else:
        print("â„¹ï¸  æº–ç¢ºç‡è¼ƒä½ï¼Œå¯èƒ½éœ€è¦æ›´å¤šç‰¹å¾µå·¥ç¨‹æˆ–åƒæ•¸èª¿æ•´")
    
    # --- 9. ç‰¹å¾µé‡è¦æ€§åˆ†æ ---
    print("\n" + "="*60)
    print("ğŸ“Š ç‰¹å¾µé‡è¦æ€§åˆ†æ (Top 10)")
    print("="*60)
    
    feature_importance = pd.DataFrame({
        'feature': available_features,
        'importance': model.feature_importances_
    }).sort_values('importance', ascending=False)
    
    print(feature_importance.head(10).to_string(index=False, float_format="%.4f"))
    
    print("\n" + "="*60)
    print("ğŸ‰ èª¿è©¦å®Œæˆï¼")
    print("="*60)

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\nâ¹ï¸  ç”¨æˆ¶ä¸­æ–·åŸ·è¡Œ")
        sys.exit(0)
    except Exception as e:
        print(f"\nâŒ ç¨‹å¼åŸ·è¡Œæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
