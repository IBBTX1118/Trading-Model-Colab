# æª”å: 5_train_final_model.py
# ç‰ˆæœ¬: 1.0
# æè¿°: ä½¿ç”¨æ‰€æœ‰å¯ç”¨æ•¸æ“šå’Œæœ€ä½³åƒæ•¸ï¼Œè¨“ç·´ä¸¦å„²å­˜ä¸€å€‹ç”¨æ–¼å¯¦ç›¤äº¤æ˜“çš„æœ€çµ‚æ¨¡å‹ã€‚

import pandas as pd
import lightgbm as lgb
import json
import yaml
from pathlib import Path
import joblib
import logging
import sys

# ==============================================================================
#                      1. è¨­å®šå€å¡Š
# ==============================================================================
# --- é¸æ“‡è¦ç‚ºå“ªå€‹å¸‚å ´è¨“ç·´æœ€çµ‚æ¨¡å‹ ---
MARKET_NAME = "EURUSD.sml_H1" # â˜…â˜…â˜… ç¢ºä¿é€™èˆ‡æ‚¨åœ¨ 6_trading_bot_template.py ä¸­è¨­å®šçš„ SYMBOL å’Œ TIMEFRAME_STR ä¸€è‡´ â˜…â˜…â˜…

# ==============================================================================
#                      2. ä¸»ç¨‹å¼é‚è¼¯
# ==============================================================================
def setup_logger():
    """è¨­å®šæ—¥èªŒè¨˜éŒ„å™¨"""
    logger = logging.getLogger("FinalModelTrainer")
    logger.setLevel(logging.INFO)
    if not logger.hasHandlers():
        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
        handler = logging.StreamHandler(sys.stdout)
        handler.setFormatter(formatter)
        logger.addHandler(handler)
    return logger

def create_labels(df: pd.DataFrame, settings: Dict) -> pd.DataFrame:
    """å¾ 4 è™Ÿè…³æœ¬ç§»æ¤éä¾†çš„æ¨™ç±¤å‰µå»ºå‡½æ•¸"""
    df_out = df.copy()
    tp_m, sl_m, max_hold = settings['tp_atr_multiplier'], settings['sl_atr_multiplier'], settings['max_hold_periods']
    
    atr_col = next((c for c in df_out.columns if 'D1_ATR_14' in c), None) or next((c for c in df_out.columns if 'ATR_14' in c), None)
    if atr_col is None: raise ValueError("æ•¸æ“šä¸­ç¼ºå°‘ ATR æ¬„ä½")
    
    outcomes = pd.Series(index=df_out.index, dtype=float, name='label')
    high_s, low_s, atr_s = df_out['high'], df_out['low'], df_out[atr_col]
    
    for i in range(len(df_out) - max_hold):
        entry, atr = df_out['close'].iloc[i], atr_s.iloc[i]
        if atr <= 0 or pd.isna(atr): continue
        tp, sl = entry + (atr * tp_m), entry - (atr * sl_m)
        highs, lows = high_s.iloc[i+1:i+1+max_hold], low_s.iloc[i+1:i+1+max_hold]
        tp_mask, sl_mask = highs >= tp, lows <= sl
        tp_time = tp_mask.idxmax() if tp_mask.any() else pd.NaT
        sl_time = sl_mask.idxmax() if sl_mask.any() else pd.NaT
        if pd.notna(tp_time) and pd.notna(sl_time): outcomes.iloc[i] = 1 if tp_time <= sl_time else -1
        elif pd.notna(tp_time): outcomes.iloc[i] = 1
        elif pd.notna(sl_time): outcomes.iloc[i] = -1
        else: outcomes.iloc[i] = 0
        
    df_out = df_out.join(outcomes)
    df_out['target_binary'] = (df_out['label'] == 1).astype(int)
    return df_out

def train_and_save_model(logger: logging.Logger):
    """åŸ·è¡Œå®Œæ•´çš„æ¨¡å‹è¨“ç·´èˆ‡å„²å­˜æµç¨‹"""
    logger.info(f"ğŸš€ é–‹å§‹ç‚ºå¸‚å ´ [{MARKET_NAME}] è¨“ç·´æœ€çµ‚æ¨¡å‹...")
    
    # --- 1. è¼‰å…¥é…ç½®å’Œè·¯å¾‘ ---
    try:
        with open('config.yaml', 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        paths = config['paths']
        tb_settings = config['triple_barrier_settings']
        
        market_folder = "_".join(MARKET_NAME.split('_')[:2])
        data_file = Path(paths['features_data']) / market_folder / f"{MARKET_NAME}.parquet"
        features_file = Path(paths['ml_pipeline_output']) / f"selected_features_{MARKET_NAME}.json"
        params_file = Path(paths['ml_pipeline_output']) / f"{MARKET_NAME}_best_params_binary_lgbm.json"
        output_model_file = Path(paths['ml_pipeline_output']) / f"final_model_{MARKET_NAME}.joblib"
        
    except Exception as e:
        logger.error(f"âŒ è®€å–é…ç½®æ–‡ä»¶æˆ–è¨­å®šè·¯å¾‘æ™‚å‡ºéŒ¯: {e}")
        return

    # --- 2. è¼‰å…¥æ‰€éœ€æª”æ¡ˆ ---
    try:
        df = pd.read_parquet(data_file)
        with open(features_file, 'r') as f:
            selected_features = json.load(f)['selected_features']
        with open(params_file, 'r') as f:
            # ä½¿ç”¨æœ€å¾Œä¸€å€‹ Fold çš„å„ªåŒ–åƒæ•¸ä½œç‚ºæˆ‘å€‘æœ€çµ‚æ¨¡å‹çš„è¶…åƒæ•¸
            best_params = json.load(f)['folds_data'][-1]
        logger.info("âœ… æ•¸æ“šã€ç‰¹å¾µåˆ—è¡¨å’Œæœ€ä½³åƒæ•¸è¼‰å…¥æˆåŠŸã€‚")
    except FileNotFoundError as e:
        logger.error(f"âŒ æ‰¾ä¸åˆ°å¿…è¦çš„æª”æ¡ˆ: {e}")
        logger.error("ğŸ’¡ è«‹ç¢ºä¿æ‚¨å·²æˆåŠŸé‹è¡Œ 2, 3, 4 è™Ÿè…³æœ¬ã€‚")
        return
        
    # --- 3. æº–å‚™æœ€çµ‚è¨“ç·´æ•¸æ“š ---
    logger.info("æ­£åœ¨æº–å‚™æœ€çµ‚è¨“ç·´æ•¸æ“š...")
    df_labeled = create_labels(df, tb_settings)
    df_train = df_labeled[df_labeled['label'] != 0].copy()
    df_train.dropna(subset=selected_features + ['target_binary'], inplace=True)
    
    X_train = df_train[selected_features]
    y_train = df_train['target_binary']
    
    if len(X_train) == 0:
        logger.error("âŒ æ¸…ç†å¾Œæ²’æœ‰å¯ç”¨çš„è¨“ç·´æ•¸æ“šï¼")
        return
    logger.info(f"ğŸ“Š æœ€çµ‚å°‡ä½¿ç”¨ {len(X_train)} ç­†æ•¸æ“šé€²è¡Œè¨“ç·´ã€‚")

    # --- 4. è¨­å®šæ¨¡å‹ä¸¦è¨“ç·´ ---
    logger.info("æ­£åœ¨è¨­å®šæ¨¡å‹åƒæ•¸ä¸¦é–‹å§‹è¨“ç·´...")
    model_params = {k: v for k, v in best_params.items() if k not in ['entry_threshold', 'tp_atr_multiplier', 'sl_atr_multiplier', 'risk_per_trade', 'fold', 'best_sharpe_in_val']}
    model_params.update({'objective': 'binary', 'metric': 'logloss', 'verbosity': -1, 'seed': 42})
    neg, pos = (y_train == 0).sum(), (y_train == 1).sum()
    if pos > 0 and neg > 0: model_params['scale_pos_weight'] = neg / pos
    
    final_model = lgb.LGBMClassifier(**model_params)
    final_model.fit(X_train, y_train)
    logger.info("âœ… æœ€çµ‚æ¨¡å‹è¨“ç·´å®Œæˆï¼")

    # --- 5. å„²å­˜æ¨¡å‹ ---
    try:
        joblib.dump(final_model, output_model_file)
        logger.info(f"ğŸ’¾ æ¨¡å‹å·²æˆåŠŸå„²å­˜è‡³: {output_model_file}")
    except Exception as e:
        logger.error(f"âŒ å„²å­˜æ¨¡å‹æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

if __name__ == "__main__":
    logger = setup_logger()
    train_and_save_model(logger)
