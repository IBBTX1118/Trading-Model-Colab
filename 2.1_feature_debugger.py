# æª”å: 2.1_feature_debugger.py
# æè¿°: å°ˆç”¨æ–¼åµéŒ¯ 02_feature_engineering.pyï¼Œæª¢æŸ¥æ¯ä¸€æ­¥çš„ NaN ç”¢ç”Ÿæƒ…æ³
# ç‰ˆæœ¬: 1.1 (ä¿®å¾©ç‰ˆ - ç§»é™¤é­”æ³•å‘½ä»¤ä¸¦å¢å¼·è¨ºæ–·åŠŸèƒ½)

import pandas as pd
import numpy as np
import yaml
from pathlib import Path
import logging
import sys
import warnings
from finta import TA
from collections import defaultdict

# å¿½ç•¥è­¦å‘Šä¿¡æ¯
warnings.filterwarnings('ignore')

# ==============================================================================
#                      é…ç½®é¡åˆ¥ (èˆ‡ 02 è™Ÿè…³æœ¬ä¿æŒä¸€è‡´)
# ==============================================================================
class Config:
    INPUT_BASE_DIR = Path("Output_Data_Pipeline_v2/MarketData")
    OUTPUT_BASE_DIR = Path("Output_Feature_Engineering/MarketData_with_Combined_Features_v3")
    LOG_LEVEL = "INFO"
    TIMEFRAME_ORDER = ['D1', 'H4', 'H1']
    EVENTS_FILE_PATH = Path("economic_events.csv")
    GLOBAL_FACTORS_FILE_PATH = Path("global_factors.parquet")

# ==============================================================================
#                      ç‰¹å¾µå·¥ç¨‹é¡åˆ¥ (ç°¡åŒ–ç‰ˆï¼Œå°ˆç”¨æ–¼èª¿è©¦)
# ==============================================================================
class FeatureEngineerDebugger:
    """ç‰¹å¾µå·¥ç¨‹èª¿è©¦å™¨ - é€æ­¥åŸ·è¡Œä¸¦æª¢æŸ¥æ¯å€‹æ­¥é©Ÿçš„æ•¸æ“šå¥åº·ç‹€æ³"""
    
    def __init__(self, config: Config):
        self.config = config
        self.logger = self._setup_logger()
        self.step_results = []  # è¨˜éŒ„æ¯å€‹æ­¥é©Ÿçš„çµæœ
        
    def _setup_logger(self) -> logging.Logger:
        logger = logging.getLogger(self.__class__.__name__)
        logger.setLevel(self.config.LOG_LEVEL.upper())
        if not logger.hasHandlers():
            formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
            sh = logging.StreamHandler(sys.stdout)
            sh.setFormatter(formatter)
            logger.addHandler(sh)
        return logger

    def _add_base_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """æ·»åŠ åŸºç¤æŠ€è¡“åˆ†æç‰¹å¾µ"""
        self.logger.debug("Adding base features...")
        df_finta = df.copy()
        
        # é‡å‘½åæˆäº¤é‡æ¬„ä½ä»¥é…åˆfinta
        df_finta.rename(columns={'tick_volume': 'volume'}, inplace=True)
        
        try:
            # ATR è¨ˆç®—
            for p in [5, 14, 20]:
                df_finta[f'ATR_{p}'] = TA.ATR(df_finta, period=p)
            
            # DMI æŒ‡æ¨™
            df_finta = df_finta.join(TA.DMI(df_finta))
            
            # ç§»å‹•å¹³å‡å’Œ RSI
            periods = [10, 20, 50]
            for indicator in ['SMA', 'EMA']:
                method = getattr(TA, indicator)
                for p in periods:
                    df_finta[f'{indicator}_{p}'] = method(df_finta, period=p)
            
            # RSI
            df_finta['RSI_14'] = TA.RSI(df_finta, period=14)
            
            # å…¶ä»–æŒ‡æ¨™
            df_finta = df_finta.join(TA.STOCH(df_finta))
            df_finta = df_finta.join(TA.MACD(df_finta))
            df_finta = df_finta.join(TA.BBANDS(df_finta))
            
            # åƒ¹æ ¼è¡Œç‚ºç‰¹å¾µ
            df_finta['body_size'] = abs(df_finta['close'] - df_finta['open'])
            df_finta['upper_wick'] = df_finta['high'] - df_finta[['open', 'close']].max(axis=1)
            df_finta['lower_wick'] = df_finta[['open', 'close']].min(axis=1) - df_finta['low']
            df_finta['body_vs_wick'] = df_finta['body_size'] / (df_finta['high'] - df_finta['low'] + 1e-9)
            
            # DMI å·®ç•°
            if 'DI+' in df_finta.columns and 'DI-' in df_finta.columns:
                df_finta['DMI_DIFF'] = abs(df_finta['DI+'] - df_finta['DI-'])
            
            # æ¨™æº–åŒ–ç‰¹å¾µ
            if 'ATR_14' in df_finta.columns:
                atr_series = df_finta['ATR_14'] + 1e-9
                df_finta['body_size_norm'] = df_finta['body_size'] / atr_series
                if 'DMI_DIFF' in df_finta.columns:
                    df_finta['DMI_DIFF_norm'] = df_finta['DMI_DIFF'] / atr_series
            
        except Exception as e:
            self.logger.error(f"åŸºç¤ç‰¹å¾µè¨ˆç®—æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        
        # æ¢å¾©åŸå§‹æ¬„ä½å
        df_finta.rename(columns={'volume': 'tick_volume'}, inplace=True)
        return df_finta

    def _add_market_microstructure_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """æ–°å¢å¸‚å ´å¾®çµæ§‹ç‰¹å¾µ"""
        self.logger.debug("Adding market microstructure features...")
        df_out = df.copy()
        
        try:
            # è²·è³£å£“åŠ›æŒ‡æ¨™
            df_out['buying_pressure'] = (df_out['close'] - df_out['low']) / (df_out['high'] - df_out['low'] + 1e-9)
            
            # åƒ¹æ ¼æ•ˆç‡æ¯”ç‡
            net_change = abs(df_out['close'].diff(20))
            total_movement = df_out['close'].diff().abs().rolling(20).sum()
            df_out['efficiency_ratio'] = net_change / (total_movement + 1e-9)
            
            # è¨‚å–®æµä¸å¹³è¡¡ä»£ç†
            ofi_proxy = (df_out['tick_volume'] * np.sign(df_out['close'].diff())).fillna(0)
            df_out['ofi_cumsum_20'] = ofi_proxy.rolling(20).sum()
            
        except Exception as e:
            self.logger.error(f"å¸‚å ´å¾®çµæ§‹ç‰¹å¾µè¨ˆç®—æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            
        return df_out

    def _add_regime_detection_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """æ–°å¢å¸‚å ´ç‹€æ…‹è­˜åˆ¥ç‰¹å¾µ"""
        self.logger.debug("Adding regime detection features...")
        df_out = df.copy()
        
        try:
            # æ³¢å‹•ç‡ç‹€æ…‹
            returns = df_out['close'].pct_change()
            df_out['volatility_20p'] = returns.rolling(20).std()
            
            # Z-score æ¨™æº–åŒ–
            vol_mean_60 = df_out['volatility_20p'].rolling(60).mean()
            vol_std_60 = df_out['volatility_20p'].rolling(60).std()
            df_out['vol_regime_zscore'] = (df_out['volatility_20p'] - vol_mean_60) / (vol_std_60 + 1e-9)
            
            # ADX è¶¨å‹¢å¼·åº¦
            try:
                adx_df = TA.ADX(df_out, period=14)
                if isinstance(adx_df, pd.DataFrame) and 'ADX' in adx_df.columns:
                    df_out['adx_14'] = adx_df['ADX']
                else:
                    df_out['adx_14'] = adx_df
                
                df_out['trend_strength'] = (df_out['adx_14'] / 100).fillna(0)
            except Exception as e:
                self.logger.warning(f"ADXè¨ˆç®—å¤±æ•—ï¼Œä½¿ç”¨æ›¿ä»£æ–¹æ³•: {e}")
                # ä½¿ç”¨ç§»å‹•å¹³å‡æ–œç‡ä½œç‚ºæ›¿ä»£
                ma_20 = df_out['close'].rolling(20).mean()
                trend_slope = ma_20.diff(10) / ma_20.shift(10)
                df_out['trend_strength'] = abs(trend_slope).fillna(0)
                df_out['adx_14'] = df_out['trend_strength'] * 100
            
            # å¸‚å ´ç‹€æ…‹åˆ†é¡
            conditions = [
                (df_out['vol_regime_zscore'] > 1) & (df_out['trend_strength'] > 0.3),   # é«˜æ³¢å‹•è¶¨å‹¢
                (df_out['vol_regime_zscore'] > 1) & (df_out['trend_strength'] <= 0.3),  # é«˜æ³¢å‹•ç›¤æ•´
                (df_out['vol_regime_zscore'] <= 1) & (df_out['trend_strength'] > 0.3),  # ä½æ³¢å‹•è¶¨å‹¢
                (df_out['vol_regime_zscore'] <= 1) & (df_out['trend_strength'] <= 0.3)   # ä½æ³¢å‹•ç›¤æ•´
            ]
            choices = [3, 2, 1, 0]
            df_out['market_regime'] = np.select(conditions, choices, default=0)
            
        except Exception as e:
            self.logger.error(f"å¸‚å ´ç‹€æ…‹è­˜åˆ¥ç‰¹å¾µè¨ˆç®—æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            
        return df_out

    def _add_advanced_volatility_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """æ·»åŠ é«˜ç´šæ³¢å‹•ç‡ç‰¹å¾µ"""
        self.logger.debug("Adding advanced volatility features...")
        df_out = df.copy()
        
        try:
            # ATR æ¯”ç‡
            if 'ATR_5' in df_out.columns and 'ATR_20' in df_out.columns:
                df_out['atr_ratio_5_20'] = df_out['ATR_5'] / (df_out['ATR_20'] + 1e-9)
            
            # ä¸Šæ¼²å’Œä¸‹è·Œæ³¢å‹•ç‡
            returns = df_out['close'].pct_change()
            upside_returns = returns.where(returns > 0, 0)
            downside_returns = returns.where(returns < 0, 0)
            
            df_out['upside_vol_20p'] = upside_returns.rolling(20).std()
            df_out['downside_vol_20p'] = downside_returns.rolling(20).std()
            df_out['vol_asymmetry'] = df_out['upside_vol_20p'] / (df_out['downside_vol_20p'] + 1e-9)
            
            # ä½¿ç”¨å‰å‘å¡«å……è™•ç† NaN
            volatility_cols = ['upside_vol_20p', 'downside_vol_20p', 'vol_asymmetry']
            df_out[volatility_cols] = df_out[volatility_cols].fillna(method='ffill')
            
        except Exception as e:
            self.logger.error(f"é«˜ç´šæ³¢å‹•ç‡ç‰¹å¾µè¨ˆç®—æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            
        return df_out

    def _add_price_action_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """æ·»åŠ åƒ¹æ ¼è¡Œç‚ºç‰¹å¾µ"""
        self.logger.debug("Adding price action features...")
        df_out = df.copy()
        
        try:
            # ç›¸å°æ–¼ç§»å‹•å¹³å‡çš„ä½ç½®
            if 'SMA_50' in df_out.columns and 'ATR_14' in df_out.columns:
                df_out['price_vs_sma50_norm'] = (df_out['close'] - df_out['SMA_50']) / (df_out['ATR_14'] + 1e-9)
            
            # ç›¸å°æ–¼å¸ƒæ—å¸¶çš„ä½ç½®
            if all(col in df_out.columns for col in ['BB_MIDDLE', 'BB_UPPER', 'BB_LOWER']):
                bb_width = df_out['BB_UPPER'] - df_out['BB_LOWER'] + 1e-9
                df_out['price_vs_bb'] = (df_out['close'] - df_out['BB_MIDDLE']) / bb_width * 2
            
            # è·é›¢é«˜ä½é»çš„Kç·šæ•¸
            window = 50
            df_out[f'bars_since_{window}p_high'] = df_out['high'].rolling(window).apply(
                lambda x: len(x) - np.argmax(x) - 1, raw=True
            )
            df_out[f'bars_since_{window}p_low'] = df_out['low'].rolling(window).apply(
                lambda x: len(x) - np.argmin(x) - 1, raw=True
            )
            
        except Exception as e:
            self.logger.error(f"åƒ¹æ ¼è¡Œç‚ºç‰¹å¾µè¨ˆç®—æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            
        return df_out

    def _add_multi_period_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """æ·»åŠ å¤šé€±æœŸç‰¹å¾µ"""
        self.logger.debug("Adding multi-period features...")
        df_out = df.copy()
        
        try:
            for n in [5, 10, 20, 60]:
                df_out[f'returns_{n}p'] = df_out['close'].pct_change(periods=n)
                # æ·»åŠ æ³¢å‹•ç‡ç‰¹å¾µ
                returns = df_out['close'].pct_change()
                df_out[f'volatility_{n}p'] = returns.rolling(window=n).std() * np.sqrt(n)
                
        except Exception as e:
            self.logger.error(f"å¤šé€±æœŸç‰¹å¾µè¨ˆç®—æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            
        return df_out

    def _add_advanced_time_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """æ·»åŠ é«˜ç´šæ™‚é–“ç‰¹å¾µ"""
        self.logger.debug("Adding advanced time features...")
        df_out = df.copy()
        
        try:
            hour = df_out.index.hour
            df_out['day_of_week'] = df_out.index.dayofweek
            df_out['hour_of_day'] = hour
            df_out['month_of_year'] = df_out.index.month
            
            # äº¤æ˜“æ™‚æ®µç‰¹å¾µ
            df_out['is_tokyo_session'] = ((hour >= 0) & (hour <= 8)).astype(int)
            df_out['is_london_session'] = ((hour >= 8) & (hour <= 16)).astype(int)
            df_out['is_ny_session'] = ((hour >= 13) & (hour <= 21)).astype(int)
            df_out['is_london_ny_overlap'] = ((hour >= 13) & (hour <= 16)).astype(int)
            
            # æ³¨æ„ï¼šé€™è£¡ä¸ä½¿ç”¨ pd.get_dummiesï¼Œå› ç‚ºæœƒç”¢ç”Ÿå¤§é‡ç¨€ç–ç‰¹å¾µ
            
        except Exception as e:
            self.logger.error(f"é«˜ç´šæ™‚é–“ç‰¹å¾µè¨ˆç®—æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            
        return df_out

    def _add_interaction_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """æ·»åŠ äº¤äº’ä½œç”¨ç‰¹å¾µ"""
        self.logger.debug("Adding interaction features...")
        df_out = df.copy()
        
        try:
            # RSI èˆ‡æ³¢å‹•ç‡çš„äº¤äº’ä½œç”¨
            if 'RSI_14' in df_out.columns and 'volatility_20p' in df_out.columns:
                df_out['RSI_x_volatility'] = (df_out['RSI_14'] - 50) * df_out['volatility_20p']
            
            # å¸‚å ´ç‹€æ…‹èˆ‡è¶¨å‹¢çš„äº¤äº’ä½œç”¨
            if 'vol_regime_zscore' in df_out.columns and 'trend_strength' in df_out.columns:
                df_out['regime_x_trend'] = df_out['vol_regime_zscore'] * df_out['trend_strength']
            
            # RSI èˆ‡åƒ¹æ ¼ä½ç½®çš„äº¤äº’ä½œç”¨
            if 'RSI_14' in df_out.columns and 'price_vs_sma50_norm' in df_out.columns:
                df_out['rsi_x_pullback'] = (df_out['RSI_14'] - 50) * df_out['price_vs_sma50_norm']
                
        except Exception as e:
            self.logger.error(f"äº¤äº’ä½œç”¨ç‰¹å¾µè¨ˆç®—æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            
        return df_out

    def report_health(self, df: pd.DataFrame, step_name: str) -> pd.DataFrame:
        """å ±å‘Šæ•¸æ“šå¥åº·ç‹€æ³"""
        print(f"\n{'='*60}")
        print(f"ğŸ” åŸ·è¡Œæ­¥é©Ÿ: {step_name}")
        print(f"{'='*60}")
        
        # åŸºæœ¬çµ±è¨ˆ
        rows_total = len(df)
        nan_count = df.isnull().sum().sum()
        
        print(f"ğŸ“Š åŸºæœ¬çµ±è¨ˆ:")
        print(f"   ç•¶å‰å½¢ç‹€: {df.shape}")
        print(f"   ç¸½ NaN æ•¸é‡: {nan_count:,}")
        print(f"   NaN æ¯”ä¾‹: {nan_count / (df.shape[0] * df.shape[1]) * 100:.2f}%")
        
        # æª¢æŸ¥å¦‚æœåŸ·è¡Œ dropna() çš„å½±éŸ¿
        df_dropped = df.dropna()
        rows_after_dropna = len(df_dropped)
        rows_lost = rows_total - rows_after_dropna
        
        print(f"ğŸ“‰ dropna() å½±éŸ¿åˆ†æ:")
        print(f"   åŸ·è¡Œå‰è¡Œæ•¸: {rows_total:,}")
        print(f"   åŸ·è¡Œå¾Œè¡Œæ•¸: {rows_after_dropna:,}")
        print(f"   æå¤±è¡Œæ•¸: {rows_lost:,} ({rows_lost/rows_total*100:.2f}%)")
        
        # å±éšªè­¦å‘Š
        if rows_after_dropna == 0 and rows_total > 0:
            print(f"ğŸš¨ğŸš¨ğŸš¨ åš´é‡è­¦å‘Šï¼šæ­¤æ­¥é©Ÿå¾ŒåŸ·è¡Œ dropna() å°‡å°è‡´æ•¸æ“šå®Œå…¨æ¸…ç©ºï¼ğŸš¨ğŸš¨ğŸš¨")
        elif rows_lost / rows_total > 0.5:
            print(f"âš ï¸  è­¦å‘Šï¼šæ­¤æ­¥é©Ÿå°è‡´è¶…é50%çš„æ•¸æ“šåŒ…å«NaNå€¼ï¼")
        elif rows_lost / rows_total > 0.2:
            print(f"âš ï¸  æ³¨æ„ï¼šæ­¤æ­¥é©Ÿå°è‡´è¶…é20%çš„æ•¸æ“šåŒ…å«NaNå€¼")
        else:
            print(f"âœ… æ•¸æ“šå¥åº·ç‹€æ³è‰¯å¥½")
        
        # åˆ†æå“ªäº›æ¬„ä½åŒ…å«æœ€å¤šNaN
        nan_by_column = df.isnull().sum()
        nan_columns = nan_by_column[nan_by_column > 0].sort_values(ascending=False)
        
        if len(nan_columns) > 0:
            print(f"\nğŸ“‹ NaN æœ€å¤šçš„å‰10å€‹æ¬„ä½:")
            for i, (col, nan_count) in enumerate(nan_columns.head(10).items()):
                percentage = nan_count / len(df) * 100
                print(f"   {i+1:2d}. {col}: {nan_count:,} ({percentage:.1f}%)")
        
        # è¨˜éŒ„çµæœ
        step_result = {
            'step_name': step_name,
            'total_rows': rows_total,
            'total_cols': df.shape[1],
            'nan_count': nan_count,
            'nan_percentage': nan_count / (df.shape[0] * df.shape[1]) * 100,
            'rows_after_dropna': rows_after_dropna,
            'rows_lost': rows_lost,
            'data_loss_percentage': rows_lost/rows_total*100 if rows_total > 0 else 0,
            'top_nan_columns': dict(nan_columns.head(5))
        }
        self.step_results.append(step_result)
        
        return df

    def run_debug_pipeline(self, df_raw: pd.DataFrame) -> pd.DataFrame:
        """é‹è¡Œå®Œæ•´çš„èª¿è©¦æµç¨‹"""
        print("ğŸš€ é–‹å§‹ç‰¹å¾µå·¥ç¨‹èª¿è©¦æµç¨‹...")
        print(f"ğŸ“Š åŸå§‹æ•¸æ“šå½¢ç‹€: {df_raw.shape}")
        
        # è¤‡è£½åŸå§‹æ•¸æ“š
        df_processed = df_raw.copy()
        
        # é€æ­¥åŸ·è¡Œç‰¹å¾µå·¥ç¨‹ä¸¦æª¢æŸ¥
        steps = [
            ("åŸå§‹æ•¸æ“š", lambda x: x),
            ("åŸºç¤ç‰¹å¾µ", self._add_base_features),
            ("å¸‚å ´å¾®çµæ§‹ç‰¹å¾µ", self._add_market_microstructure_features),
            ("å¸‚å ´ç‹€æ…‹è­˜åˆ¥ç‰¹å¾µ", self._add_regime_detection_features),
            ("é«˜ç´šæ³¢å‹•ç‡ç‰¹å¾µ", self._add_advanced_volatility_features),
            ("åƒ¹æ ¼è¡Œç‚ºç‰¹å¾µ", self._add_price_action_features),
            ("å¤šé€±æœŸç‰¹å¾µ", self._add_multi_period_features),
            ("é«˜ç´šæ™‚é–“ç‰¹å¾µ", self._add_advanced_time_features),
            ("äº¤äº’ä½œç”¨ç‰¹å¾µ", self._add_interaction_features),
        ]
        
        for step_name, step_func in steps:
            try:
                if step_name != "åŸå§‹æ•¸æ“š":
                    df_processed = step_func(df_processed)
                df_processed = self.report_health(df_processed, step_name)
            except Exception as e:
                print(f"âŒ æ­¥é©Ÿ '{step_name}' åŸ·è¡Œå¤±æ•—: {e}")
                import traceback
                traceback.print_exc()
                break
        
        return df_processed

    def generate_summary_report(self):
        """ç”Ÿæˆç¸½çµå ±å‘Š"""
        print(f"\n{'='*80}")
        print("ğŸ“ˆ ç‰¹å¾µå·¥ç¨‹èª¿è©¦ç¸½çµå ±å‘Š")
        print(f"{'='*80}")
        
        if not self.step_results:
            print("âŒ æ²’æœ‰æ­¥é©Ÿçµæœå¯ä¾›åˆ†æ")
            return
        
        print(f"{'æ­¥é©Ÿåç¨±':<20} {'è¡Œæ•¸':<10} {'åˆ—æ•¸':<8} {'NaN%':<8} {'æå¤±%':<8} {'ç‹€æ…‹'}")
        print("-" * 80)
        
        for result in self.step_results:
            status = "ğŸš¨å±éšª" if result['rows_after_dropna'] == 0 else \
                    "âš ï¸è­¦å‘Š" if result['data_loss_percentage'] > 20 else \
                    "âœ…æ­£å¸¸"
            
            print(f"{result['step_name']:<20} "
                  f"{result['total_rows']:<10,} "
                  f"{result['total_cols']:<8} "
                  f"{result['nan_percentage']:<7.1f}% "
                  f"{result['data_loss_percentage']:<7.1f}% "
                  f"{status}")
        
        # æ‰¾å‡ºå•é¡Œæ­¥é©Ÿ
        problem_steps = [r for r in self.step_results if r['data_loss_percentage'] > 50]
        
        if problem_steps:
            print(f"\nâš ï¸  ç™¼ç¾ {len(problem_steps)} å€‹å•é¡Œæ­¥é©Ÿ:")
            for step in problem_steps:
                print(f"   â€¢ {step['step_name']}: æå¤± {step['data_loss_percentage']:.1f}% çš„æ•¸æ“š")
                if step['top_nan_columns']:
                    print(f"     ä¸»è¦NaNæ¬„ä½: {list(step['top_nan_columns'].keys())[:3]}")

def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸš€ ç‰¹å¾µå·¥ç¨‹èª¿è©¦å·¥å…· v1.1")
    print("="*60)
    
    # --- è¨­å®š ---
    MARKET_NAME = "EURUSD_sml_H4"
    RAW_DATA_PATH = Path("Output_Data_Pipeline_v2/MarketData")
    
    print(f"ğŸ¯ ç›®æ¨™å¸‚å ´: {MARKET_NAME}")
    print(f"ğŸ“ æ•¸æ“šè·¯å¾‘: {RAW_DATA_PATH}")
    
    # --- è¼‰å…¥åŸå§‹æ•¸æ“š ---
    print(f"\nğŸ“‚ è¼‰å…¥åŸå§‹æ•¸æ“š...")
    
    raw_market_folder = MARKET_NAME.split('_')[0] + "_" + MARKET_NAME.split('_')[1]
    raw_data_file = RAW_DATA_PATH / raw_market_folder / f"{MARKET_NAME}.parquet"
    
    if not raw_data_file.exists():
        print(f"âŒ æ•¸æ“šæª”æ¡ˆä¸å­˜åœ¨: {raw_data_file}")
        print("ğŸ’¡ è«‹ç¢ºèªè·¯å¾‘è¨­å®šæ˜¯å¦æ­£ç¢º")
        return
    
    try:
        df_raw = pd.read_parquet(raw_data_file)
        print(f"âœ… æˆåŠŸè¼‰å…¥åŸå§‹æ•¸æ“š: {df_raw.shape}")
        print(f"   æ™‚é–“ç¯„åœ: {df_raw.index.min()} åˆ° {df_raw.index.max()}")
        print(f"   æ¬„ä½: {list(df_raw.columns)}")
    except Exception as e:
        print(f"âŒ æ•¸æ“šè¼‰å…¥å¤±æ•—: {e}")
        return
    
    # --- åŸ·è¡Œèª¿è©¦æµç¨‹ ---
    config = Config()
    debugger = FeatureEngineerDebugger(config)
    
    try:
        df_final = debugger.run_debug_pipeline(df_raw)
        debugger.generate_summary_report()
        
        print(f"\nğŸ‰ èª¿è©¦æµç¨‹å®Œæˆï¼")
        print(f"   æœ€çµ‚æ•¸æ“šå½¢ç‹€: {df_final.shape}")
        
    except Exception as e:
        print(f"âŒ èª¿è©¦æµç¨‹åŸ·è¡Œå¤±æ•—: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\nâ¹ï¸  ç”¨æˆ¶ä¸­æ–·åŸ·è¡Œ")
        sys.exit(0)
    except Exception as e:
        print(f"\nâŒ ç¨‹å¼åŸ·è¡Œæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
