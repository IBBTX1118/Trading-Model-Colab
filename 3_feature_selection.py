# æª”å: 3_feature_selection_with_diagnostics.py
# ç‰ˆæœ¬: 5.0 (æ•´åˆè¨ºæ–·ç‰ˆ)
# æè¿°: åœ¨ç‚ºæ‰€æœ‰å¸‚å ´é€²è¡Œç‰¹å¾µç¯©é¸å‰ï¼Œå…ˆå°ä¸€å€‹æ¨£æœ¬å¸‚å ´åŸ·è¡Œå¿«é€Ÿè¨ºæ–·ã€‚

import logging
import sys
import json
import yaml
from pathlib import Path
from typing import List, Dict
from collections import defaultdict
import pandas as pd
import numpy as np
import lightgbm as lgb

# ==============================================================================
#                      1. å¿«é€Ÿè¨ºæ–·å·¥å…· (ä¾†è‡ª 0_quick_diagnostics.py)
# ==============================================================================
class QuickDiagnostics:
    """å¿«é€Ÿè¨ºæ–·æ•¸æ“šã€æ¨™ç±¤å’ŒåŸºç¤ç­–ç•¥çš„å¥åº·ç‹€æ³"""
    def __init__(self, config_path: Path = Path("config.yaml")):
        self.logger = logging.getLogger(self.__class__.__name__)
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
            self.tb_settings = config['triple_barrier_settings']
            self.paths = config['paths']
            self.logger.info("âœ… (è¨ºæ–·å™¨) é…ç½®æª”è¼‰å…¥æˆåŠŸ")
        except Exception as e:
            self.logger.critical(f"âŒ (è¨ºæ–·å™¨) é…ç½®æª”è¼‰å…¥å¤±æ•—: {e}")
            raise

    def check_data_files(self, market_name: str):
        self.logger.info("\nğŸ” (è¨ºæ–·) æª¢æŸ¥æ•¸æ“šæª”æ¡ˆ...")
        features_dir = Path(self.paths['features_data'])
        market_folder = "_".join(market_name.split('_')[:2])
        market_file = features_dir / market_folder / f"{market_name}.parquet"
        
        if not market_file.exists():
            self.logger.error(f"âŒ ç‰¹å¾µæ•¸æ“šæª”æ¡ˆä¸å­˜åœ¨: {market_file}")
            return False
        self.logger.info(f"âœ… æ‰¾åˆ°ç›®æ¨™å¸‚å ´ç‰¹å¾µæª”æ¡ˆ: {market_file}")
        return True

    def check_sample_data(self, market_name: str) -> Optional[pd.DataFrame]:
        self.logger.info(f"\nğŸ” (è¨ºæ–·) æª¢æŸ¥ {market_name} æ•¸æ“šå“è³ª...")
        features_dir = Path(self.paths['features_data'])
        market_folder = "_".join(market_name.split('_')[:2])
        data_file = features_dir / market_folder / f"{market_name}.parquet"
        try:
            df = pd.read_parquet(data_file)
            self.logger.info(f"âœ… æˆåŠŸè¼‰å…¥æ•¸æ“šï¼Œå…± {len(df)} ç­†è¨˜éŒ„")
            missing_ratio = df.isnull().sum().sum() / df.size
            self.logger.info(f"ğŸ“Š ç¼ºå¤±å€¼æ¯”ä¾‹: {missing_ratio:.2%}")
            if missing_ratio > 0.1: self.logger.warning("âš ï¸ ç¼ºå¤±å€¼éå¤š")
            return df
        except Exception as e:
            self.logger.error(f"âŒ è¼‰å…¥æ•¸æ“šå¤±æ•—: {e}")
            return None

    def test_label_creation(self, df: pd.DataFrame, max_samples=1000) -> Optional[pd.DataFrame]:
        self.logger.info(f"\nğŸ·ï¸  (è¨ºæ–·) æ¸¬è©¦æ¨™ç±¤å‰µå»º...")
        df_test = df.tail(max_samples).copy()
        atr_col = next((c for c in df_test.columns if 'ATR_14' in c), None)
        if atr_col is None: self.logger.error("âŒ æ‰¾ä¸åˆ° ATR_14 æ¬„ä½"); return None
        
        try:
            df_labeled = self._create_simple_labels(df_test, atr_col)
            label_counts = df_labeled['label'].value_counts().sort_index()
            total = len(df_labeled.dropna(subset=['label']))
            self.logger.info("ğŸ“Š æ¨™ç±¤åˆ†å¸ƒ:")
            for label, count in label_counts.items():
                name = {1: 'æ­¢ç›ˆ', -1: 'æ­¢æ', 0: 'æŒæœ‰'}[label]
                self.logger.info(f"   {name}: {count} ({count/total:.1%})")
            if total > 0 and (label_counts.min() / total) < 0.1:
                self.logger.warning("âš ï¸ æ¨™ç±¤å¯èƒ½ä¸å¹³è¡¡")
            return df_labeled
        except Exception as e:
            self.logger.error(f"âŒ æ¨™ç±¤å‰µå»ºå¤±æ•—: {e}")
            return None

    def _create_simple_labels(self, df, atr_col):
        df_out = df.copy()
        tp_m, sl_m, hold = self.tb_settings['tp_atr_multiplier'], self.tb_settings['sl_atr_multiplier'], self.tb_settings['max_hold_periods']
        outcomes = pd.Series(np.nan, index=df_out.index)
        for i in range(len(df_out) - hold):
            entry = df_out['close'].iloc[i]; atr = df_out[atr_col].iloc[i]
            if atr <= 0 or pd.isna(atr): continue
            tp, sl = entry + (atr * tp_m), entry - (atr * sl_m)
            future = df_out.iloc[i+1:i+1+hold]
            hit_tp = (future['high'] >= tp).any(); hit_sl = (future['low'] <= sl).any()
            if hit_tp and hit_sl:
                tp_idx = future[future['high'] >= tp].index[0]
                sl_idx = future[future['low'] <= sl].index[0]
                outcomes.iloc[i] = 1 if tp_idx <= sl_idx else -1
            elif hit_tp: outcomes.iloc[i] = 1
            elif hit_sl: outcomes.iloc[i] = -1
            else: outcomes.iloc[i] = 0
        df_out['label'] = outcomes
        return df_out

    def run_full_diagnosis(self, market_name: str):
        self.logger.info(f"\n{'='*80}\nğŸš€ é–‹å§‹å°æ¨£æœ¬å¸‚å ´ [{market_name}] é€²è¡Œå¿«é€Ÿè¨ºæ–·...\n{'='*80}")
        if not self.check_data_files(market_name): return
        df = self.check_sample_data(market_name)
        if df is None: return
        self.test_label_creation(df)
        self.logger.info(f"\n{'='*80}\nğŸš€ å¿«é€Ÿè¨ºæ–·å®Œç•¢ã€‚\n{'='*80}")


# ==============================================================================
#                      2. ç‰¹å¾µç¯©é¸å™¨ (ä¾†è‡ª 3_feature_selection.py)
# ==============================================================================
class FeatureSelector:
    # ... æ­¤è™•çš„ FeatureSelector class çš„æ‰€æœ‰å…§å®¹èˆ‡æ‚¨æä¾›çš„
    # ... 3_feature_selection.py å®Œå…¨ç›¸åŒï¼Œç‚ºäº†ç°¡æ½”æ­¤è™•çœç•¥ã€‚
    # ... è«‹å°‡æ‚¨åŸæœ¬çš„ FeatureSelector class å…§å®¹å®Œæ•´è¤‡è£½åˆ°é€™è£¡ã€‚
    def __init__(self, config_path: Path = Path("config.yaml")):
        self.logger = logging.getLogger(self.__class__.__name__)
        self.config_path = config_path
        with open(config_path, 'r', encoding='utf-8') as f:
            self.config = yaml.safe_load(f)
        self.tb_settings = self.config['triple_barrier_settings']
        self.fs_config = self.config['feature_selection']
        self.paths = self.config['paths']
        self.output_dir = Path(self.paths['ml_pipeline_output'])
        self.output_dir.mkdir(parents=True, exist_ok=True)
    def get_feature_importance_for_file(self, df: pd.DataFrame) -> pd.DataFrame:
        non_feature_cols = ['open', 'high', 'low', 'close', 'tick_volume', 'target', 'time', 'spread', 'real_volume', 'label', 'hit_time']
        # ä½¿ç”¨è‡ªé©æ‡‰æ¨™ç±¤
        df_labeled = create_adaptive_labels(df, self.tb_settings)
        features = [col for col in df_labeled.columns if col not in non_feature_cols]
        X, y = df_labeled[features], df_labeled['target']
        combined = pd.concat([X, y], axis=1).dropna()
        X, y = combined[features], combined['target']
        if len(X) == 0 or len(y.value_counts()) < 2: return pd.DataFrame({'feature': [], 'importance': []})
        try:
            model = lgb.LGBMClassifier(**self.fs_config['lgbm_params'])
            model.fit(X, y)
            return pd.DataFrame({'feature': features, 'importance': model.feature_importances_})
        except Exception as e: self.logger.error(f"æ¨¡å‹è¨“ç·´å¤±æ•—: {e}"); return pd.DataFrame({'feature': [], 'importance': []})
    def save_selected_features(self, features: List[str], market_name: str):
        output_path = self.output_dir / f"selected_features_{market_name}.json"
        self.logger.info(f"æ­£åœ¨å°‡ {market_name} çš„ç‰¹å¾µå„²å­˜åˆ°: {output_path}")
        output_data = {"description": f"ç‚ºå¸‚å ´ {market_name} ç”¢ç”Ÿçš„å°ˆå±¬ç‰¹å¾µåˆ—è¡¨", "market": market_name,
                       "feature_count": len(features), "selected_features": features,
                       "generation_settings": {"top_n_features": self.fs_config['top_n_features'], "triple_barrier_settings": self.tb_settings}}
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(output_data, f, indent=4, ensure_ascii=False)
    def run(self):
        self.logger.info(f"\n{'='*80}\nğŸš€ é–‹å§‹æ­£å¼ç‰¹å¾µç¯©é¸æµç¨‹...\n{'='*80}")
        input_dir = Path(self.paths['features_data'])
        all_files = list(input_dir.rglob("*.parquet"))
        if not all_files: self.logger.warning("åœ¨è¼¸å…¥ç›®éŒ„ä¸­æ²’æœ‰æ‰¾åˆ°ä»»ä½•æª”æ¡ˆã€‚"); return
        market_files = defaultdict(list)
        for f in all_files: market_files[f.stem].append(f)
        self.logger.info(f"ç™¼ç¾ {len(market_files)} å€‹å¸‚å ´çµ„éœ€è¦è™•ç†: {list(market_files.keys())}")
        for market_name, files in market_files.items():
            self.logger.info(f"\n--- é–‹å§‹è™•ç†å¸‚å ´: {market_name} ---")
            all_importances = []
            for file_path in files:
                try:
                    df = pd.read_parquet(file_path)
                    importance_df = self.get_feature_importance_for_file(df)
                    if not importance_df.empty: all_importances.append(importance_df)
                except Exception as e: self.logger.error(f"è™•ç†æª”æ¡ˆ {file_path.name} æ™‚å‡ºéŒ¯: {e}", exc_info=True)
            if not all_importances: self.logger.warning(f"å¸‚å ´ {market_name} æœªèƒ½è¨ˆç®—ä»»ä½•ç‰¹å¾µé‡è¦æ€§ï¼Œå·²è·³éã€‚"); continue
            market_importance = pd.concat(all_importances).groupby('feature')['importance'].sum().sort_values(ascending=False)
            top_features = market_importance.head(self.fs_config['top_n_features']).index.tolist()
            self.logger.info(f"âœ… ç‚º {market_name} é¸å‡ºæœ€é‡è¦çš„ {len(top_features)} å€‹ç‰¹å¾µã€‚")
            self.save_selected_features(top_features, market_name)
        self.logger.info(f"\n{'='*80}\nğŸš€ ç‰¹å¾µç¯©é¸æµç¨‹å®Œç•¢ã€‚\n{'='*80}")

# --- è¼”åŠ©å‡½å¼ create_adaptive_labels å’Œ create_triple_barrier_labels ---
# ... é€™å…©å€‹å‡½æ•¸ä¹Ÿéœ€è¦å¾æ‚¨åŸæœ¬çš„ 3_feature_selection.py è¤‡è£½éä¾† ...
def create_adaptive_labels(df: pd.DataFrame, settings: Dict) -> pd.DataFrame:
    df_out = df.copy()
    tp_base, sl_base, max_hold = settings['tp_atr_multiplier'], settings['sl_atr_multiplier'], settings['max_hold_periods']
    adj = {0: 0.8, 1: 0.9, 2: 1.1, 3: 1.2}
    if 'market_regime' in df_out.columns:
        df_out['tp_adj'] = df_out['market_regime'].map(adj) * tp_base
        df_out['sl_adj'] = df_out['market_regime'].map(adj) * sl_base
    else:
        df_out['tp_adj'] = tp_base; df_out['sl_adj'] = sl_base
    atr_col = 'D1_ATR_14' if 'D1_ATR_14' in df_out.columns else 'ATR_14'
    if atr_col not in df_out.columns: raise ValueError(f"ç¼ºå°‘ ATR æ¬„ä½")
    outcomes = pd.DataFrame(index=df_out.index, columns=['label'])
    high_s, low_s, atr_s = df_out['high'], df_out['low'], df_out[atr_col]
    tp_mult, sl_mult = df_out['tp_adj'], df_out['sl_adj']
    for i in range(len(df_out) - max_hold):
        entry, atr, tp_m, sl_m = df_out['close'].iloc[i], atr_s.iloc[i], tp_mult.iloc[i], sl_mult.iloc[i]
        if atr <= 0 or pd.isna(atr) or pd.isna(tp_m) or pd.isna(sl_m): continue
        tp, sl = entry + (atr * tp_m), entry - (atr * sl_m)
        win_high, win_low = high_s.iloc[i+1:i+1+max_hold], low_s.iloc[i+1:i+1+max_hold]
        tp_mask, sl_mask = win_high >= tp, win_low <= sl
        hit_tp_time = win_high[tp_mask].index.min() if tp_mask.any() else pd.NaT
        hit_sl_time = win_low[sl_mask].index.min() if sl_mask.any() else pd.NaT
        if pd.notna(hit_tp_time) and pd.notna(hit_sl_time): outcomes.loc[df_out.index[i], 'label'] = 1 if hit_tp_time < hit_sl_time else -1
        elif pd.notna(hit_tp_time): outcomes.loc[df_out.index[i], 'label'] = 1
        elif pd.notna(hit_sl_time): outcomes.loc[df_out.index[i], 'label'] = -1
        else: outcomes.loc[df_out.index[i], 'label'] = 0
    df_out = df_out.join(outcomes); df_out['target'] = (df_out['label'] == 1).astype(int)
    df_out.drop(columns=['tp_adj', 'sl_adj'], inplace=True, errors='ignore')
    return df_out
# ==============================================================================
#                      3. ä¸»åŸ·è¡Œå€å¡Š
# ==============================================================================
if __name__ == "__main__":
    # --- åŸºæœ¬è¨­å®š ---
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', stream=sys.stdout)
    CONFIG_PATH = Path("config.yaml")
    DIAGNOSTICS_MARKET_SAMPLE = "EURUSD_sml_H4" # æŒ‡å®šä¸€å€‹ç”¨æ–¼å¿«é€Ÿè¨ºæ–·çš„æ¨£æœ¬å¸‚å ´

    try:
        # --- æ­¥é©Ÿ 1: åŸ·è¡Œå¿«é€Ÿè¨ºæ–· ---
        diagnostics = QuickDiagnostics(config_path=CONFIG_PATH)
        diagnostics.run_full_diagnosis(market_name=DIAGNOSTICS_MARKET_SAMPLE)
        
        # --- æ­¥é©Ÿ 2: åŸ·è¡Œæ­£å¼çš„ç‰¹å¾µç¯©é¸ ---
        selector = FeatureSelector(config_path=CONFIG_PATH)
        selector.run()

    except Exception as e:
        logging.critical(f"è…³æœ¬åŸ·è¡Œæ™‚ç™¼ç”Ÿæœªé æœŸçš„åš´é‡éŒ¯èª¤: {e}", exc_info=True)
        sys.exit(1)
